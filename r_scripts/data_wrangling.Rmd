---
title: "Pakistan data summary"
output:
  html_document: default
bibliography:   all_refs.bib
csl: biomed-central.csl
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = F)
library(knitr)
library(dplyr)
library(janitor)
library(qgraph)
library(ape)
library(TransPhylo)
library(coda)
fmt <- function(x, ...){format(x, big.mark=",",scientific=FALSE, ...)}
knitr::opts_chunk$set(echo = F)
# options(scipen=1, digits=2)
options(scipen=999, digits = 3)
table_font_sz <- 8

```

```{r functions, echo = F}

# Functions ----

heaD <- function(x,...){
  head(x, ...)
}

len_str <- function(string){
  length(unlist(strsplit(string, split = "")))
}

hs <- function(x, ...){
  print(head(x, ...))
  print("---")
  str(x, ...)
}

to_table <- function(x, pc_dir = "row"){
  # pc_dir = the direction to use for calculating percentages. One of "row", "col", or "all".
  x <- x %>% adorn_totals(c("row", "col")) %>%
    adorn_percentages(c(pc_dir)) %>%
    adorn_pct_formatting(digits = 2)
  formatted_ns <- attr(x, "core") %>% # extract the tabyl's underlying Ns
    adorn_totals(c("row", "col")) %>% # to match the data.frame we're appending to
    dplyr::mutate_if(is.numeric, format, big.mark = ",")
  x %>% adorn_ns(position = "front", ns = formatted_ns)
}

```

```{r variables, echo = F}

# Variables ----
id_col <- "wgs_id"
rnd <- 2
drugs <- c("rifampicin", "isoniazid", "ethambutol", "pyrazinamide", "streptomycin", 
             "ofloxacin", "moxifloxacin", "levofloxacin", "amikacin", "kanamycin", "capreomycin", "ciprofloxacin", "prothionamide", 
             "ethionamide", "para_aminosalicylic_acid", "cycloserine",
             "clarithromycin", "clofazimine", "bedaquiline", "linezolid", "rifabutin", "delamanid")
align <- c("l", "r", "r")
col <- "cornflowerblue"
threshold <- 50
plot_text_sz <- 0.5

```

```{r paths, echo = F}

# Paths ----

metadata_path <- "../metadata/"
plots_path <- "../plots/"
db_path <- "../../pipeline/db/"
dist_path <- "../dist_and_pca/"
beast_results_path <- "../beast_results/"

```

```{r files, echo = F}

# Files ----
metadata_file <- paste0(metadata_path, "pakistan_metadata.csv")
historical_metadata_file <- paste0(metadata_path, "historical_metadata.csv") # http://www.pasteur-guadeloupe.fr/
tree_all_samps_file <- paste0(plots_path, "PAKISTAN_ALL.tree.png")
lineage_conversion_file <- paste0(db_path, "lineage_conversions.txt")
dist_file <- paste0(dist_path, "PAKISTAN_ALL.dist.dist")
dist_id_file <- paste0(dist_path, "PAKISTAN_ALL.dist.dist.id")
mcc_tree_file <- paste0(beast_results_path, "PAKISTAN_ALL.mcc.tree")
beast_log_file <- paste0(beast_results_path, "PAKISTAN_ALL.log")
methods_file <- paste0(metadata_path, "pakistan_methods.tsv")

```

```{r read_in_data, echo = F}

# Read in data ----

metadata <- read.csv(metadata_file)
historical_metadata <- read.csv(historical_metadata_file)
lineage_conversions <- read.delim(lineage_conversion_file)
dist <- read.delim(dist_file, header = F)
dist_id <- read.delim(dist_id_file, header = F)
mcc_tree <- ape::read.nexus(mcc_tree_file)
beast_log <- tracerer::parse_beast_log(beast_log_file)
methods_table <- read.table(file = methods_file, sep = '\t', header = TRUE)

```

```{r basic_numbers, echo = F}

# Basic numbers and basic wrangling ----

n_samps_total <- length(metadata$wgs_id)
n_snps_total <- 37970

# Subset metadata to just those with a year
metadata_dated <- subset(metadata, !(is.na(metadata$year)))
dated_samps <- metadata_dated$wgs_id

# Add row and col names to distance matrix
colnames(dist) <- dist_id[, 1]
row.names(dist) <- dist_id[, 1]
# Divide dist matrix by 2 
dist <- dist/2

```


```{r table_1}

# Table 1 ----

# https://www.nature.com/articles/s41598-019-45566-5/tables/1

# Table 1 - Mycobacterium tuberculosis samples (N = 178)

# Characteristic	N	%
# 
# Location*
#   
# Lineages
# 
# Drug resistance**
# 
# Rifampicin
# Isoniazid...etc
# 
# Dr type
# MDR-TB...etc


# Lineages
lin_tab <- reshape2::dcast(metadata, main_lineage ~ "N", value.var = id_col, fun.aggregate = length)
names(lin_tab) <- c("Lineages", names(lin_tab)[length(names(lin_tab))])
lin_tab$pc <- round((lin_tab$N/sum(lin_tab$N)) * 100, rnd)

# Lineages conversions
lin_conv <- merge(metadata["sub_lineage"], lineage_conversions, 
                  by.x = "sub_lineage", by.y = "mtbc_lineage", 
                  all.x = T, sort = F)
lin_conv_tab <- reshape2::dcast(lin_conv, sub_lineage + lsp_lineage + spoligotype_family + rd_number ~ "N",
                                value.var = "sub_lineage", fun.aggregate = length)
names(lin_conv_tab) <- c("Sub lineage", "LSP lineage", "Spoligotype family", "RD number", "N")


# DR
# Specific drugs
drugs_data <- apply(metadata[drugs], 2, as.numeric)
dr_tab <- as.data.frame(t(t(apply(drugs_data[, drugs], 2, sum, na.rm = T))))
dr_tab$drug_resistance <- row.names(dr_tab)
names(dr_tab) <- c("N", "Drug resistance")
dr_tab <- dr_tab[c("Drug resistance", "N")]
row.names(dr_tab) <- NULL
dr_tab$pc <- round((dr_tab$N/sum(dr_tab$N)) * 100, rnd)

# DR status
# Desired order of DR cols
dr_vals <- c("Sensitive", "Pre-MDR", "MDR", "Pre-XDR", "XDR", "Other") 
dr_status_tab <- reshape2::dcast(metadata, dr_status ~ "N", value.var = id_col, fun.aggregate = length)
dr_status_tab <- dr_status_tab[match(dr_vals, dr_status_tab$dr_status), ]
names(dr_status_tab) <- c("Drug resistance status", names(dr_status_tab)[length(names(dr_status_tab))])
dr_status_tab$pc <- round((dr_status_tab$N/sum(dr_status_tab$N)) *100, rnd)
row.names(dr_status_tab) <- NULL

# DR status by lineage
dr_lin_tab <- reshape2::dcast(metadata,  dr_status ~ main_lineage, value.var = id_col, fun.aggregate = length)
dr_lin_tab$dr_status <- factor(dr_lin_tab$dr_status, levels = dr_vals)
dr_lin_tab <- dr_lin_tab[order(dr_lin_tab$dr_status), ]
names(dr_lin_tab) <- c("DR status", paste0("L", sort(unique(metadata$main_lineage))))
dr_lin_tab <- to_table(dr_lin_tab, pc_dir = "all")

```


## Introduction

In 2019 [@WHO_2020]: 

* Pakistan is a high-burden TB country (population 216.6 million).
* One of eight countries accounting for two thirds of the global total TB instance (5.7%).
* HIV prevalence is increasing. 190,000 people living with HIV (0.1 prevalence); 25,000 new infections. [@UNAIDS_2020]
* High burden for multidrug-resistance (MDR-TB, resistance to isoniazid and rifampicin treatments (see table below).
* However overall treatment success rate is 93% and the mortality rate has been declining since at least 2000. 


**Estimates of TB burden, 2019**

| | Number | (Rate per 100,000 population) |
|-----------|-----------|-----------|
| Total TB incidence | 570,000 (404,000-764,000)	| 263 (187-353) |
| HIV-positive TB incidence |	5,100 (3,400-7,200)	| 2.4 (1.6-3.3) |
| MDR/RR-TB incidence | 25,000 (16,000-36,000) | 12 (7.3-17) |
| HIV-negative TB mortality |	42,000 (34,000-51,000) | 19 (16-24) | 
| HIV-positive TB mortality	| 1,900 (1,300-2,800)	| 0.9 (0.58-1.3) |

**Estimated proportion of TB cases with MDR/RR-TB, 2019**

|  |  |
|-----------|-----------|
| New cases |	4.2% (3.2-5.3) |
| Previously treated cases |	7.3% (6.8-7.8) |


### Historical genomic data on MTBC in Pakistan [@Demay2012]

```{r historical, echo=FALSE, out.width = "2000px"}

n_samps_historical <- length(historical_metadata$IsoNumber)

title <- sprintf("Number of samples by spoligotype family \n in historical Mtb data from Pakistan, n = %s", n_samps_historical)
barplot(table(historical_metadata$Clade), las=2, 
        main = title, col = col)

```



*Mycobacterium tuberculosis* samples (N = `r n_samps_total`)

### Lineages tables

```{r lintables, echo=FALSE, out.width = "2000px"}

knitr::kable(lin_tab, align = align)
knitr::kable(lin_conv_tab)

```

### Drug resistance tables

```{r drtable, echo=FALSE, out.width = "2000px"}

knitr::kable(dr_tab, align = align)
knitr::kable(dr_lin_tab)

```


## Tree

The `r n_samps_total` *M. tuberculosis* isolates: A phylogenetic tree constructed using `r fmt(n_snps_total)` SNPs

```{r treeAllSamps, echo=FALSE, out.width = "2000px"}

knitr::include_graphics(tree_all_samps_file)

```


## Dates

```{r dates, echo=FALSE, out.width = "2000px"}

year <- metadata$year[!is.na(metadata$year)]
years <- sort(unique(year))
breaks <- (min(year)-0.5):(max(year)+0.5)
yr_hist <- hist(year, freq = T, xaxt="n", xlab= "year",
                breaks = breaks, col = col, 
                main = sprintf("Hist of year; n = %s", length(year)))
axis(side = 1, at = yr_hist$mids, labels = years)

```

## Transmission

### Distances 

#### All samples

```{r distanceall, echo=FALSE, out.width = "2000px"}

# Summary of distances for all samples
lower_dist <- dist[lower.tri(dist)]
summary(lower_dist)
boxplot(lower_dist, col = col, 
        main = sprintf("SNP distances (excluding DR sites), all samples; \n n = %s", nrow(dist)))

```

#### Dated samples

```{r distancedated, echo=FALSE, out.width = "2000px"}

# Summary of dists for dated samples 
dist_dated <- dist[dated_samps, dated_samps]
lower_dist_dated <- dist_dated[lower.tri(dist_dated)]
summary(lower_dist_dated)
boxplot(lower_dist_dated, col = col, 
        main = sprintf("SNP distances (excluding DR sites), dated samples; \n n = %s", nrow(dist_dated)))

# dist_dated <- as.dist(dist_dated)

# Convert to 'distance matrix' (take out lower triangle)
dist_dated[upper.tri(dist_dated, diag = T)] <- 0

# Cluster using 'single' method.
# Clusters all samples within distance of threshold
clust <- hclust(as.dist(dist_dated), method = "single")
plot(clust, cex = 0.5,
     main = sprintf("Clustering of SNP distances, dated samples; n = %s. \n Line at %s ", 
                    nrow(dist_dated), threshold))
abline(a = threshold, b = 0)
# Cut tree at threshold to find samples within threshold
clusters <- sort(cutree(clust, h = threshold))

# Filter for clusters (take out the samples with their own number, i.e., those not in a group)
# Gets samples below the threshold
clusters <- clusters[clusters %in% names(which(table(clusters) > 1)) ]

# Subset
dist_dated_thresh <- as.dist(dist_dated[sort(names(clusters)), sort(names(clusters))])
dist_dated_thresh <- dist_dated_thresh+1 # Add 1 because 1/x later.

qgraph(1/dist_dated_thresh, layout='spring', vsize=5, 
       title = sprintf("Connections among samples with <= %s SNP distance; n = %s",
                       threshold, length(attributes(dist_dated_thresh)$Labels)))


```


### Beast results

#### Beast parameters & priors:

Parameters & priors are based on Xu (2020) [@Xu2020]

| Beauti tab | Selection | Parameter values [min, max] |
|:----------------------|:----------------------|:----------------------|
| Site model | GTR/Gamma Site Model | gamma distribution [0, inf.] |
| | |prior frequencies (estimated) [0, 1] |
| | | Proportion invariant = 0 |
|Correction for ascertainment bias ("constantSiteWeights") [added manually] | | no. of invariant A, C, G & T sites = 758511, 1449901, 1444524, 758336 |
| Clock model | Strict clock                                           | Clock rate = 1.0E-7 (0.44 substitutions per genome per year ) |
| Priors      | Population size model = Coalescent Constant Population | Pop size = log normal(100 [0, 200])                           |
|             | MRCA  ("TreePrior")                                    | Laplace distribution                                          |
|             |                                                        | Mu = 0                                                        |
| MCMC        |      | iterations = 100000000 |
|             |      | Sample every = 10000   |


```{r beastresultslineages, echo=FALSE, out.width = "1000px"}
# Beast mcc tree for L2, 3, 4

# l2_mcc <- ape::read.nexus("../beast_results/l2.mcc.tree")
# l3_mcc <- ape::read.nexus("../beast_results/l3.mcc.tree")
# l4_mcc <- ape::read.nexus("../beast_results/l4.mcc.tree")
# 
# # Get last date from tree
# first_date <- as.numeric(min(unlist(lapply(strsplit(mcc_tree$tip.label, "_"), function(x){x[length(x)]}))))
# last_date <- as.numeric(max(unlist(lapply(strsplit(mcc_tree$tip.label, "_"), function(x){x[length(x)]}))))
# 
# plot_text_sz <- 1
# x_lim <- c(2010, last_date_l2+10)
# vline <- 2020
#   col <- "red"
# x_labs <- seq(0, last_date_l2, by = 1)
# 
# par(mfrow=c(1,3))
# 
# # Convert ape phylo object into phylogenetic tree. Pass last date.
# plot(l2_mcc, cex = plot_text_sz, x.lim = x_lim)
# abline(v = last_date, col = col)
# axis(1, at = x_labs, labels = x_labs)
# 
# plot(l3_mcc, cex = plot_text_sz, x.lim = x_lim)
# abline(v = last_date, col = col)
# axis(1, at = x_labs, labels = x_labs)
# 
# plot(l4_mcc, cex = plot_text_sz, x.lim = x_lim)
# abline(v = last_date, col = col)
# axis(1, at = x_labs, labels = x_labs)

```


```{r beastresults, echo=FALSE, out.width = "1500px"}

# Get last date from tree
first_date <- mcc_tree$root.edge
last_date <- as.numeric(max(unlist(lapply(strsplit(mcc_tree$tip.label, "_"), function(x){x[length(x)]}))))

x_lim <- c(last_date-10, last_date+10)
col <- "red"
x_labs_full <- seq(first_date, last_date, by = 500)
x_labs_zoom <- seq(last_date-10, last_date, by = 1)

# Convert ape phylo object into phylogenetic tree. Pass last date.
# ptree <- TransPhylo::ptreeFromPhylo(mcc_tree, dateLastSample=last_date)
plot(mcc_tree, cex = plot_text_sz, 
     main = sprintf("Beast MCC tree of all dated samples, \n n = %s", length(mcc_tree$tip.label)))
abline(v = last_date, col = col)
axis(1, at = x_labs_full, labels = x_labs_full, cex.axis = plot_text_sz)

plot(mcc_tree, cex = plot_text_sz, x.lim = x_lim,
     main = "As above, zoomed into tips")
for(i in x_labs_zoom){
  abline(v = i, col = col)
}
axis(1, at = x_labs_zoom, labels = x_labs_zoom, cex.axis = plot_text_sz)


```

#### Beast log file means and ESS values 

```{r beastlog, echo=FALSE, out.width = "1500px"}

# Results of beast log

# Remove the burn-in
beast_log <- tracerer::remove_burn_ins(
  beast_log,
  burn_in_fraction = 0.1
)

# Calculates the effective sample sizes of all parameter estimates
esses <- t(tracerer::calc_esses(beast_log, sample_interval = 1000))

# Get means
means <- apply(beast_log, 2, mean)
means <- means[!(names(means) %in% "Sample")]

# Combine
log_table <- cbind(means, esses)
colnames(log_table) <- c("Mean", "ESS")
log_table <- round(log_table, 2)

log_table

```


### Methods
```{r methods, echo=FALSE, out.width = "1500px"}

kable(methods_table)

```


#### 

### References













